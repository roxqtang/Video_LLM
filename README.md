# Video_LLM

## Related Papers

| Category | Paper | Authors | Published Date | Conference/Journal |
|----------|-------|---------|---------------|-------------------|
| **Video Understanding** | [VideoLLM: Modeling Video Understanding with Large Language Models](https://arxiv.org/abs/2305.13292) | Guo, et al. | May 2023 | arXiv |
| | [Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding](https://arxiv.org/abs/2306.02858) | Zhang, et al. | June 2023 | ICCV 2023 |
| | [LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models](https://arxiv.org/abs/2311.17043) | Dai, et al. | Nov 2023 | arXiv |
| **Video Generation** | [VideoPoet: A Large Language Model for Zero-Shot Video Generation](https://arxiv.org/abs/2312.14125) | Yu, et al. | Dec 2023 | arXiv |
| | [Gen-2: The Next Step Forward in General-Purpose Video Models](https://arxiv.org/abs/2312.05612) | Esser, et al. | Dec 2023 | arXiv |
| | [VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models](https://arxiv.org/abs/2502.02492) | Chefer, et al. | Feb 2025 | arXiv |
| | [Flowvid: Taming imperfect optical flows for consistent video-to-video synthesis](https://arxiv.org/abs/2401.10797) | Misra, et al. | Jan 2024 | arXiv |
| **Vision-Language Models** | [LLaVA1 : Visual Instruction Tuning](https://arxiv.org/abs/2304.08485) | Liu, et al. | Dec 2023 | arXiv |
| | [LLaVA-1.5: Visual Improved Baselines with Visual Instruction Tuning](https://arxiv.org/abs/2310.03744) | Liu, et al. | Dec 2023 | arXiv |
| | [Sparse Attention Vectors: Generative Multimodal Model Features Are Discriminative Vision-Language Classifiers](https://arxiv.org/abs/2401.05159) | Darrell, et al. | Jan 2024 | arXiv |
| | [Analyzing The Language of Visual Tokens](https://arxiv.org/abs/2402.18476) | Misra, Darrell, et al. | Feb 2024 | arXiv |
| | [CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning](https://arxiv.org/abs/2402.09575) | Du, et al. | Feb 2024 | arXiv |
| | [CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts](https://arxiv.org/abs/2401.13601) | Shi, et al. | Jan 2024 | arXiv |
| **Vision Transformers** | [Token Merging: Your ViT But Faster](https://openreview.net/pdf?id=JroZRaRw7Eu) | Bolya, et al. | Mar 2023 | ICLR 2023 |
| | [Scaling White-Box Transformers for Vision](https://arxiv.org/abs/2402.06039) | Ma, et al. | Feb 2024 | arXiv |
| | [White-Box Transformers via Sparse Rate Reduction](https://proceedings.neurips.cc/paper_files/paper/2023/hash/65d2ea03425887a717c435081cfc5dbb-Abstract-Conference.html) | Ma, et al. | Dec 2023 | NeurIPS 2023 |
| | [Eyes wide shut](https://arxiv.org/abs/2401.14167) | Ma, et al. | Jan 2024 | arXiv |
| **Language Models** | [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) | Beltagy, et al. | Apr 2020 | arXiv |
| | [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) | Radford, et al. | 2019 | OpenAI |
| | [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971) | Touvron, et al. | Feb 2023 | arXiv |
| | [DeepSeekV3: Technical Report](https://arxiv.org/html/2412.19437v1) | Deeoseek-AI | Dec 2024 | arXiv |
| | [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948) | Guo, et al. | Jan 2025 | arXiv |
| **Model Compression** | [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/abs/1510.00149) | Han, et al. | Oct 2015 | ICLR 2016 |
| | [Learning Structured Sparsity in Deep Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2016/file/41bfd20a38bb1b0bec75acf0845530a7-Paper.pdf) | Wen, et al. | 2016 | NeurIPS 2016 |
| | [Rethinking the Value of Network Pruning](https://openreview.net/pdf?id=rJlnB3C5Ym) | Liu, et al. | 2019 | ICLR 2019 |
| | [A Simple and Effective Pruning Approach for Large Language Models](https://openreview.net/pdf?id=PxoFut3dWW) | Frantar, et al. | 2023 | ICLR 2023 |
| | [SVDQuant](https://arxiv.org/abs/2402.05917) | Zhu, et al. | Feb 2024 | arXiv |
| **Quantization** | [Trained Ternary Quantization](https://openreview.net/pdf?id=S1_pAu9xl) | Zhu, et al. | 2017 | ICLR 2017 |
| | [Incremental Network Quantization](https://openreview.net/pdf?id=HyQJ-mclg) | Zhou, et al. | 2017 | ICLR 2017 |
| | [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://ieeexplore.ieee.org/abstract/document/8578384) | Jacob, et al. | 2018 | CVPR 2018 |
| | [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://proceedings.mlr.press/v202/xiao23c.html) | Xiao, et al. | 2023 | ICML 2023 |
| **Neural Architecture & Optimization** | [Learning from Multiple Teacher Networks](https://dl.acm.org/doi/10.1145/3097983.3098135) | You, et al. | 2017 | KDD 2017 |
| | [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://openreview.net/pdf?id=rJlnB3C5Ym) | Wei, et al. | 2022 | NeurIPS 2022 |
| | [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://ieeexplore.ieee.org/abstract/document/8954198) | Tan, et al. | 2019 | CVPR 2019 |
| | [FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search](https://ieeexplore.ieee.org/abstract/document/8953587) | Wu, et al. | 2019 | CVPR 2019 |
| **Efficient Training & Inference** | [Neural Gradients Are Near-Lognormal: Improved Quantized and Sparse Training](https://openreview.net/pdf?id=EoFNy62JgDd) | Dong, et al. | 2023 | ICLR 2023 |
| | [LoRA: Low-Rank Adaptation of Large Language Models](https://openreview.net/pdf?id=nZeVKeeFYf9) | Hu, et al. | 2021 | NeurIPS 2021 |
| | [COAT: Compressing Optimizer States and Activation for Memory-Efficient FP8 Training](https://arxiv.org/abs/2410.19313) | Xu, et al. | Oct 2023 | arXiv |
| | [Federated Optimization in Heterogeneous Networks](https://proceedings.mlsys.org/paper_files/paper/2020/hash/1f5fe83998a09396ebe6477d9475ba0c-Abstract.html) | Li, et al. | 2020 | MLSys 2020 |
| **Distributed & Mobile Computing** | [TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning](https://proceedings.neurips.cc/paper/2017/hash/89fcd07f20b6785b92134bd6c1d0fa42-Abstract.html) | Wen, et al. | 2017 | NeurIPS 2017 |
| | [Modnn: Local Distributed Mobile Computing System for Deep Neural Networks](https://ieeexplore.ieee.org/document/7927211) | Mao, et al. | 2017 | IEEE VR 2017 |
| | [MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://openreview.net/pdf?id=PEpUb0bfJv) | Chen, et al. | 2024 | ICLR 2024 |
| | [Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting](https://arxiv.org/abs/2404.18911) | Xu, et al. | Apr 2024 | arXiv |
| **Continuous Tokenization** | [Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens](https://arxiv.org/abs/2410.13863) | Fan, et al. | Oct 2024 | arXiv |
| | [Autoregressive Image Generation without Vector Quantization](https://arxiv.org/abs/2406.11838) | Chen, et al. | Jun 2024 | arXiv |
| | [Rank-N-Contrast: Learning Continuous Representations for Regression](https://proceedings.neurips.cc/paper_files/paper/2023/hash/39e9c5913c970e3e49c2df629daff636-Abstract-Conference.html) | Zha, et al. | 2023 | NeurIPS 2023 |
| | [Return of Unconditional Generation: A Self-supervised Representation Generation Method](https://openreview.net/forum?id=clTa4JFBML) | Li, et al. | Sep 2024 | NeurIPS 2024 oral |
| **Multimodal** | [H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation](https://arxiv.org/abs/2307.01486) | Shi, et al. | Jul 2023 | MICCAI 2023 |
| | [CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion](https://arxiv.org/abs/2211.14461) | Zhao, et al. | Apr 2023 | CVPR 2023 |

