# Video_LLM

## Related Papers

### Video Understanding

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [VideoLLM: Modeling Video Understanding with Large Language Models](https://arxiv.org/abs/2305.13292) | Guo, et al. | May 2023 | arXiv |
| [Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding](https://arxiv.org/abs/2306.02858) | Zhang, et al. | June 2023 | ICCV 2023 |
| [LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models](https://arxiv.org/abs/2311.17043) | Dai, et al. | Nov 2023 | arXiv |

### Video Generation

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [VideoPoet: A Large Language Model for Zero-Shot Video Generation](https://arxiv.org/abs/2312.14125) | Yu, et al. | Dec 2023 | arXiv |
| [Gen-2: The Next Step Forward in General-Purpose Video Models](https://arxiv.org/abs/2312.05612) | Esser, et al. | Dec 2023 | arXiv |

### Reasoning  and LLM

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [DeepSeekV3: Technical Report](https://arxiv.org/html/2412.19437v1) | Deeoseek-AI | Dec 2024 | arXiv |
| [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948) | Guo, et al. | Jan 2025 | arXiv |


### Representation Learning

### Multimodal

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [LLaVA1 : Visual Instruction Tuning](https://arxiv.org/abs/2304.08485) | Liu, et al. | Dec 2023 | arXiv |
| [LLaVA-1.5: Visual Improved Baselines with Visual Instruction Tuning](https://arxiv.org/abs/2310.03744) | Liu, et al. | Dec 2023 | arXiv |
| [Molmo]

### Efficient Transformer

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [Token Merging: Your ViT But Faster](https://openreview.net/pdf?id=JroZRaRw7Eu) | Bolya, et al. | Mar 2023 | ICLR 2023 |
| [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) | Beltagy, et al. | Apr 2020 | arXiv |
| [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) | Radford, et al. | 2019 | OpenAI |
| [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971) | Touvron, et al. | Feb 2023 | arXiv |

### Model Compression

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/abs/1510.00149) | Han, et al. | Oct 2015 | ICLR 2016 |
| [Learning Structured Sparsity in Deep Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2016/file/41bfd20a38bb1b0bec75acf0845530a7-Paper.pdf) | Wen, et al. | 2016 | NeurIPS 2016 |
| [Rethinking the Value of Network Pruning](https://openreview.net/pdf?id=rJlnB3C5Ym) | Liu, et al. | 2019 | ICLR 2019 |
| [A Simple and Effective Pruning Approach for Large Language Models](https://openreview.net/pdf?id=PxoFut3dWW) | Frantar, et al. | 2023 | ICLR 2023 |

### Quantization

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [Trained Ternary Quantization](https://openreview.net/pdf?id=S1_pAu9xl) | Zhu, et al. | 2017 | ICLR 2017 |
| [Incremental Network Quantization](https://openreview.net/pdf?id=HyQJ-mclg) | Zhou, et al. | 2017 | ICLR 2017 |
| [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://ieeexplore.ieee.org/abstract/document/8578384) | Jacob, et al. | 2018 | CVPR 2018 |
| [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://proceedings.mlr.press/v202/xiao23c.html) | Xiao, et al. | 2023 | ICML 2023 |

### Neural Architecture & Optimization

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [Learning from Multiple Teacher Networks](https://dl.acm.org/doi/10.1145/3097983.3098135) | You, et al. | 2017 | KDD 2017 |
| [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://openreview.net/pdf?id=rJlnB3C5Ym) | Wei, et al. | 2022 | NeurIPS 2022 |
| [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://ieeexplore.ieee.org/abstract/document/8954198) | Tan, et al. | 2019 | CVPR 2019 |
| [FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search](https://ieeexplore.ieee.org/abstract/document/8953587) | Wu, et al. | 2019 | CVPR 2019 |

### Efficient Training & Inference

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [Neural Gradients Are Near-Lognormal: Improved Quantized and Sparse Training](https://openreview.net/pdf?id=EoFNy62JgDd) | Dong, et al. | 2023 | ICLR 2023 |
| [LoRA: Low-Rank Adaptation of Large Language Models](https://openreview.net/pdf?id=nZeVKeeFYf9) | Hu, et al. | 2021 | NeurIPS 2021 |
| [COAT: Compressing Optimizer States and Activation for Memory-Efficient FP8 Training](https://arxiv.org/abs/2410.19313) | Xu, et al. | Oct 2023 | arXiv |
| [Federated Optimization in Heterogeneous Networks](https://proceedings.mlsys.org/paper_files/paper/2020/hash/1f5fe83998a09396ebe6477d9475ba0c-Abstract.html) | Li, et al. | 2020 | MLSys 2020 |

### Distributed & Mobile Computing

| Paper | Authors | Published Date | Conference/Journal |
|-------|---------|---------------|-------------------|
| [TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning](https://proceedings.neurips.cc/paper/2017/hash/89fcd07f20b6785b92134bd6c1d0fa42-Abstract.html) | Wen, et al. | 2017 | NeurIPS 2017 |
| [Modnn: Local Distributed Mobile Computing System for Deep Neural Networks](https://ieeexplore.ieee.org/document/7927211) | Mao, et al. | 2017 | IEEE VR 2017 |
| [MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://openreview.net/pdf?id=PEpUb0bfJv) | Chen, et al. | 2024 | ICLR 2024 |
| [Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting](https://arxiv.org/abs/2404.18911) | Xu, et al. | Apr 2024 | arXiv |

## Citation